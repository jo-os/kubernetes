# Почему появился Kubernetes

**Kubernetes** – это платформа с открытым исходным кодом для размещения контейнеров и определения прикладных API для управления облачной семантикой обеспечения этих контейнеров хранилищами данных, сетевыми услугами, поддержкой безопасности и другими ре- сурсами. Kubernetes обеспечивает непрерывную синхронизацию все- го пространства состояний ваших приложений, в том числе способов доступа к ним из внешнего мира.

**Основыне теримины:**
- CNI (Container Networking Interface) и CSI (Container Storage Inter- face) – сетевой интерфейс контейнеров и интерфейс хранилища для контейнеров соответственно; позволяют подключать к се- тям и хранилищам модули Pod (с контейнерами), работающие в Kubernetes;
- контейнер (Container) – образ Docker или OCI (Open Container Ini- tiative), который обычно запускает приложение;
- плоскость управления (Control plane) – мозг кластера Kubernetes, осуществляющий планирование контейнеров и управляющий всеми объектами Kubernetes (которые иногда называют мастер- объектами);
- набор демонов (DaemonSet) – аналог развертывания (Deployment), но выполняется на каждом узле кластера;
- развертывание (Deployment) – набор модулей, которыми управ- ляет Kubernetes;
- kubectl – инструмент командной строки для взаимодействия с панелью управления Kubernetes;
- kubelet – агент Kubernetes, работающий на узлах кластера. Обе- спечивает поддержку плоскости управления;
- узел (Node) – машина, на которой запущен процесс kubelet;
- OCI (Open Container Initiative) – общий формат образа для созда- ния выполняемых автономных приложений. Также называется образами Docker;
- Pod (модуль) – объект Kubernetes, инкапсулирующий действую- щий контейнер.

Kubernetes дает возможность централизовать управление пространством состояний всех приложений с использованием одного удобного инструмента: kubectl – клиента командной строки, выполняющего вызовы REST API к серверу Kubernetes API.

Kubernetes использует привилегированный контейнер в среде Linux, он может управлять правилами iptables для организации маршрутизации трафика к приложениям, что, собственно, и делает прокси-сервер Kubernetes Service - kube-proxy. Контейнеры оказываются фундаментальным примитивом и для запуска приложений, и для управления инфраструктурой, которые запускают сервисы, необходимые приложениям (специализированные хранилища или брандмауэры с определенными настройками), и, что особенно важно, сами приложения. Kubernetes практически бесспорно считается современным стандартом для организации и запуска контейнеров в любом облачном окружении, на сервере или в центре обработки данных.

### Контейнеры и образы

Docker можно рассматривать как способ запуска контейнеров, где контейнер – это работающий образ OCI. Спецификация OCI – это стандартный способ определения образа, который может быть запущен такой программой, как Docker, и в конечном счете представляет собой архив с различными слоями. Контейнеры добавляют слой изоляции, устраняющий необходимость управления библиотеками на сервере или предварительной загрузки инфраструктуры другими зависимостями приложений. Использование контейнеров немыслимо без автоматизации, и именно этой цели служит Kubernetes.

### Базовая основа Kubernetes

Все сущее в Kubernetes определяется в виде простых текстовых файлов в формате YAML или JSON, и платформа запускает образы OCI декларативным способом. Kubernetes позволяет определить желаемое состоя- ние всех приложений в кластере, их подключение к сети, место работы, используемое хранилище и т. д., делегируя базовую реализацию этих деталей самой платформе Kubernetes.

Традиционные правила инфраструктуры:
- конфигурация портов или IP-маршрутов;
- постоянная доступность хранилища для приложений;
- размещение программного обеспечения на определенных или произвольных серверах;
- обеспечение безопасного доступа приложений друг к другу с использованием, например, RBAC или сетевых правил;
- конфигурация DNS для каждого приложения и глобально.

Все эти компоненты определяются в конфигурационных файлах, представляющих объекты в Kubernetes API. Kubernetes использует эти стандартные блоки и контейнеры, применяет изменения, отслеживает эти изменения и устраняет сбои или нарушения, пока не будет достигнуто желаемое конечное состояние.

### Возможности Kubernetes

Платформы оркестрации контейнеров позволяют разработчикам автоматизировать процесс запуска экземпляров, подготовки хостов, связывания контейнеров для оптимизации процедур оркестрации и продления жизненных циклов приложений. 

Основные возможности платформы оркестрации контейнеров:
- предоставления доступа, не зависящего от используемой облачной технологии, ко всем возможностям сервера API;
- интеграции со всеми основными облачными платформами и гипервизорами в диспетчере контроллеров Kubernetes (Kubernetes Controller Manager, KCM);
- обеспечения отказоустойчивости для хранения и определения состояния всех сервисов, приложений и конфигураций центров обработки данных или других инфраструктур, поддерживаемых Kubernetes;
- управления развертыванием, чтобы минимизировать время простоя отдельных узлов, сервисов или приложений;
- автоматизации масштабирования хостов и приложений с поддержкой постоянного обновления;
- создания внутренних и внешних соединений (известных как типы ClusterIP, NodePort или LoadBalancer Service) с балансировкой нагрузки;
- предоставления возможности планирования запуска приложе- ний на определенном виртуализированном оборудовании на основе его метаданных с помощью маркировки узлов и планировщика Kubernetes;
- обеспечения высокой доступности с помощью DaemonSets и других технологических инфраструктур, в которых приоритет
отдается контейнерам, работающим на всех узлах кластера;
- обнаружения сервисов через службу доменных имен, ранее реализованную как KubeDNS, а совсем недавно – CoreDNS, которая интегрируется с сервером API;
- запуска пакетных процессов (известных как задания), которые используют хранилище и контейнеры так же, как обычные приложения;
- расширения API и создания собственных программ, управляемых API, с помощью пользовательских определений ресурсов и без создания каких-либо сопоставлений портов или подключений;
- проверки сбойных процессов на уровне кластера, включая удаленное выполнение в любом контейнере в любое время с помощью kubectl exec и kubectl describe;
- подключения локального и/или удаленного хранилища к контейнеру и декларативного управления томами хранилища с помощью StorageClass API и PersistentVolumes.

Если вам не нужны высокая доступность, масштабируемость и оркестрация, то, возможно, вам не нужна Kubernetes.

### Компоненты и архитектура Kubernetes
- аппаратная инфраструктура – включает компьютеры, сетевую инфраструктуру, инфраструктуру хранения и реестр контейнеров;
- рабочие узлы Kubernetes – базовая вычислительная единица в кластере Kubernetes;
- плоскость управления Kubernetes – основа Kubernetes. Она включает сервер API, планировщика, диспетчера контроллеров и другие контроллеры.

### Kubernetes API

Администрирование микросервисов и других контейнерных приложений на платформе Kubernetes сводится к объявлению объектов Kubernetes API. Сервер Kubernetes API – kube-apiserver – позволяет выполнять CRUD-операции (Create, Read, Update, Delete – создавать, читать, обновлять, удалять) со всеми объектами и предоставляет интерфейс передачи репрезентативного состояния RESTful (REpresentational State Transfer).

Все объекты Kubernetes API имеют:
- именованную версию API (например, v1 или rbac.authorization. k8s.io/v1);
- тип (например, kind: Deployment);
- раздел метаданных.

Существует около 70 различных типов API, просмотреть их командой **kubectl api-resources**.

**Когда не стоит использовать Kubernetes**
- высокопроизводительные вычисления (High-Performance Comput- ing, HPC) – контейнеры добавляют дополнительные сложности, а наличие нового уровня бьет по производительности.
- унаследованные приложения – некоторые приложения имеют требования к оборудованию, программному обеспечению и задержке, что затрудняет их контейнеризацию.
- миграция – реализации унаследованных систем могут быть на- столько жесткими, что их миграция в Kubernetes не дает особых преимуществ

# Зачем нужны модули Pod?

Pod – это наименьшая атомарная единица, которую можно развернуть в кластере Kubernetes. Определение Pod описывает модуль, способный включать несколько контейнеров, что позволяет Kubernetes создать несколько контейнеров на узле. Многие другие объекты Kubernetes API либо используют Pod напрямую, либо являются объектами API, поддерживающими Pod. Некоторые контроллеры Kubernetes высокого уровня запускают модули Pod и управляют ими.

### Что такое Pod?

Pod – это модуль, содержащий один или несколько образов OCI, которые выполняются в контейнерах на одном узле кластера Kubernetes. Узел Kubernetes – это отдельная единица вычислительной инфраструктуры (сервер), на которой выполняется kubelet.
```yml
apiVersion: v1
kind: Pod
metadata:
spec:
  container:
    - name: busybox
      image: mycontainerregistry.io/foo
```
**kubectl create -f pod.yaml**

Команда kubectl – это двоичный выполняемый файл, реализующий интерфейс командной строки к серверу Kubernetes API.

**kubectl get po** - посмотреть Pod

### Пространства имен в Linux

Пространства имен Linux – это функция ядра Linux, позволяющая разделять процессы. Pod имеет следующие пространства имен Linux:
- одно или несколько пространств имен PID;
- единое сетевое пространство имен;
- пространство имен IPC;
- пространство имен cgroup (управляющая группа);
- пространство имен mnt (монтирование);
- пространство имен user (ID пользователя).

Пространства имен Linux – это компоненты файловой системы ядра Linux, обеспечивающие базовую функциональность для получения образа и создания работающего контейнера.

### Kubernetes, инфраструктура и Pod

Единица вычислительной мощности в Kubernetes представлена объектом узла Node. Некоторые требования к узлу:
-  сервер;
-  установленная операционная система (ОС), Linux или Windows, с необходимыми зависимостями;
- systemd (диспетчер системных служб, в Linux);
- kubelet (агент узла);
- среда выполнения контейнеров (например, Docker);
- сетевой прокси-сервер (kube-proxy), обслуживающий сервисы Kubernetes;
- провайдер сетевого интерфейса контейнеров (Container Network Interface, CNI).

**kubelet** – это двоичная программа, играющая роль агента и взаимодействующая с сервером Kubernetes API посредством поддержки цикла управления. Она работает на каждом узле; без этой программы узел Kubernetes недоступен планировщику и не может считаться частью кластера.

kubelet гарантирует:
- запуск любых модулей Pod, запланированных для выполнения на данном хосте механизмом управления, который следит за распределением модулей Pod между узлами;
- регулярное уведомление сервера API об исправной работе kubelet отправкой контрольных сообщений (Kubernetes 1.17+) с помощью механизма в пространстве имен kube-node-lease кластера;
- своевременное освобождение ресурсов, выделенных для Pod, включая эфемерные хранилища или сетевые устройства.

**kubelet не может выполнять свои обязанности без провайдера CNI и среды выполнения**, доступной через интерфейс среды выполнения контейнеров (Container Runtime Interface, CRI). CNI обслуживает потребности CRI, который затем запускает и останавливает контейнеры. **kubelet использует CRI и CNI для согласования состояния узла с состоянием плоскости управления**.

**Сервис (Service)** – это объект API, определяемый платформой Kubernetes. Двоичный файл сетевого прокси Kubernetes (kube-proxy) создает на каждом узле сервисы ClusterIP и NodePort. Вот некоторые типы сервисов:
- ClusterIP – внутренний балансировщик, распределяющий нагрузку между модулями Pod в кластере Kubernetes;
- NodePort – открытый порт на узле Kubernetes, распределяющий нагрузку между несколькими модулями Pod;
- LoadBalancer – внешний сервис, создающий балансировщик нагрузки, внешний по отношению к кластеру.

### Объект Node

Узлы поддерживают модули Pod, а плоскость управления определяет группу узлов, на которых работают контроллеры, диспетчер контроллеров и планировщик. Получить список узлов кластера - **kubectl get no**

Объект Node, описывающий узел, где размещена плоскость управления Kubernetes - **kubectl get no kind-control-plane -o yaml**

Модули Pod реализуют возможность развертывания образов. Образы развертываются на узле, а их жизненным циклом управляет kubelet. Объекты сервисов управляются сетевым прокси Kubernetes. Сетевой прокси Kubernetes обеспечивает возможность балансировки нагрузки внутри кластера, а также аварийное переключение, обновление, высокую доступность и масштабирование. Комбинация из пространства имен mnt в Linux, агента kubelet и объекта узла Node позволяет подключить диск к Pod.

### Сервер Kubernetes API: kube-apiserver

Сервер Kubernetes API (kube-apiserver) – это HTTP REST-сервер, экспортирующий различные объекты API для кластера Kubernetes, такие как Pod, Node или HorizontalPodAutoscaler. Сервер API предоставляет веб-интерфейс для выполнения операций CRUD с состоянием кластера. Сервер API – единственный компонент в плоскости управления, взаимодействующий с etcd, базой данных Kubernetes. По сути, сервер API предоставляет интерфейс для всех операций, изменяющих состояние кластера Kubernetes. Сервер API не имеет состояния и может работать на нескольких узлах одновременно. Перед серверами API в плоскости управления, состоящей из нескольких узлов, размещается балансировщик нагрузки HTTPS. В состав сервера API вхо- дят контроллеры доступа, обеспечивающие аутентификацию и авторизацию клиентов. Вызов, отправленный командой kubectl, проходит аутентификацию, а затем сервер API сохраняет новый объект развертывания в etcd. Следующий шаг – уведомление планировщика о необходимости запустить модуль Pod на узле.

### Планировщик Kubernetes: kube-scheduler

**Планировщик Kubernetes (kube-scheduler)** предлагает чистую и простую реализацию планирования, идеально подходящую для такой сложной системы, как Kubernetes. При планировании модулей Pod он учитывает несколько факторов, таких как аппаратная конфигурация узла, доступные вычислительные ресурсы и объем памяти, ограничения политик планирования и др. Планировщик также следует правилам соответствия/несоответствия (affinity/anti-affinity), определяющим порядок планирования и размещения модулей Pod. По сути, правила соответствия определяют силу притяжения модулей Pod к узлам, отвечающим требованиям, тогда как правила несоответствия определяют силу отталкивания. Ограничения (Taint), дополняющие правила, позволяют узлам отклонять определенные типы модулей, а это означает, что планировщик может определить, какие модули и на каких узлах не должны находиться. Планировщик выбирает узлы для размещения реплик, а затем планирует развертывание модулей Pod на них. Жизненным циклом модуля Pod управляет агент kubelet. Он действует как мини-планировщик для узла. Как только планировщик Kubernetes обновит NodeName в определении Pod, kubelet развернет этот модуль на своем узле.

### Контроллеры инфраструктуры

Инфраструктура поддержки контроллеров - Диспетчер контроллеров Kubernetes (Kubernetes Controller Manager, KCM) или компонент kube-controller-manager и облачный диспетчер контроллеров (Cloud Controller Manager, CCM).

**Контроллеры** – это программные компоненты, управляющие жизненным циклом модулей Pod. К ним относятся kubelet, облачный диспетчер контроллеров (CCM) и планировщик.

Объекты API PersistentVolume (PV) и PersistentVolumeClaim (PVC) определяют хранилища и воплощаются в реальность диспетчерами KCM и CCM. Одна из ключевых особенностей Kubernetes – возможность работать на множестве платформ: в облаке, на «голом железе» или на ноутбуке. Однако хранилища и другие компоненты различаются на разных платформах. KCM – это набор циклов управления, запускающих различные компоненты, называемые контроллерами, на узле, находящемся в плоскости управления. Это один двоичный файл, но он управляет несколькими циклами и, соответственно, контроллерами.

При развертывании в облачном окружении платформа Kubernetes напрямую взаимодействует с API общедоступного или частного облака, и большинство соответствующих вызовов API выполняет CCM. Цель этого компонента – запускать контроллеры, специфичные для облака, и выполнять вызовы к API облака. Вот список этих контроллеров:
- контроллер узлов – выполняет тот же код, что и KCM;
- контроллер маршрутизации – настраивает маршруты в используемой облачной инфраструктуре;
- контроллер сервисов – создает, обновляет и удаляет балансировщики нагрузки облачного провайдера;
- контроллер томов – создает, подключает и монтирует тома, а также взаимодействует с облачным провайдером, осуществляя управление томами.

Разрабатываются другие интерфейсы для поддержки более модульного и независимого от провайдеров услуг будущего Kubernetes:
- сетевой интерфейс контейнеров (Container Network Interface, CNI) – предоставляет IP-адреса модулям Pod;
- интерфейс среды выполнения контейнеров (Container Runtime Interface, CRI) – определяет и подключает различные механизмы выполнения контейнеров;
- интерфейс хранилища для контейнеров (Container Storage Interface, CSI) – модульный способ поддержки новых типов хранилищ без необходимости изменять код Kubernetes.

kubelet создает модуль Pod, он определяет нужное хранилище и подключает его к контейнеру через пространство имен mnt Linux. После этого приложение может пользоваться хранилищем. При создании сервиса LoadBalancer вместо ClusterIP облачный провайдер Kubernetes «наблюдает» за запросом балансировщика и выполняет его. Контроллер KCM, выполняя цикл наблюдения, обнаруживает потребность в новом балансировщике нагрузки и выполняет вызовы API, необходимые для создания балансировщика в облаке, или вызывает аппаратный балансировщик нагрузки, внешний по отношению к кластеру Kubernetes.

### Масштабирование, высокодоступные приложения и плоскость управления

Выполняя масштабирование, kubectl может увеличивать и уменьшать количество модулей Pod в кластере. Он работает непосредственно с наборами реплик, состояний и другими объектами API, которые используют модули Pod
```
kubectl scale --replicas 300 deployment zeus-front-end-ui
```
Сбои можно разбить на три основные категории: сбой модуля Pod, сбой узла и сбой обновления программного обеспечения.
- сбой модуля Pod. За жизненный цикл модулей Pod отвечает агент kubelet, который выполняет запуск, остановку и перезапуск модулей. Выход модуля Pod из строя определяется по отсутствию контрольных сообщений от него или по аварийному завершению процесса. В этом случае kubelet пытается перезапустить модуль.
- сбой узла. Один из циклов управления в kubelet постоянно сообщает серверу API об исправности узла. Если узел присылает контрольные сообщения недостаточно часто, то контроллер KCM меняет его статус на «вне сети» и планировщик перестает планировать модули Pod для запуска на этом узле. Модули, действовавшие на узле, планируются для удаления, а затем переносятся на другие узлы.
- сбой в обновлении программного обеспечения. Обновление развертываний осуществляется простым изменением версии образа в определении YAML и обычно выполняется одним из трех способов:
  - kubectl edit – принимает объект Kubernetes API на входе и открывает локальный терминал для редактирования объекта API на месте;
  - kubectl apply – принимает файл на входе и отыскивает объект API, соответствующий этому файлу, автоматически заменяя его;
  - kubectl patch – применяет небольшой файл с исправлениями, определяющий различия для объекта.

### Автоматическое масштабирование

Три формы автоматического масштабирования:
- создание большего количества модулей Pod (горизонтальное автоматическое масштабирование с помощью HorizontalPodAutoscaler);
- предоставление модулям Pod большего количества ресурсов (вертикальное автоматическое масштабирование с помощью VerticalPodAutoscaler);
- создание дополнительных узлов (с помощью ClusterAutoscaler).

### Управление затратам

Kubernetes поддерживает возможность плотного размещения модулей Pod, что позволяет запускать узлы с избыточными ресурсами и высокой плотностью модулей. Плотность Pod контролируется с помощью следующих шагов.
- Масштабируйте и профилируйте свои приложения. Приложения должны быть протестированы и тщательно проверены как на предмет потребления памяти, так и центрального процессора. После профилирования можно правильно определить потребности приложения в ресурсах.
- Выберите размер узла. Это позволит упаковать несколько приложений на одном узле. Запуск виртуальных машин разных размеров или серверов без системного программного обеспечения с разной емкостью позволяет сэкономить деньги и развернуть на них больше модулей Pod. При этом вы должны обеспечить достаточно большое количество узлов для поддержания высокой доступности в соответствии с требованиями SLA.
- Сгруппируйте определенные приложения вместе на определенных узлах. Это обеспечит наибольшую плотность. Ограничения и допуски позволяют шаблону Operator (Оператор) группировать модули и управлять их развертыванием.

Еще фактор, который необходимо учитывать, – это шумные соседи. В зависимости от рабочей нагрузки некоторые из настроек могут оказаться неподходящими. Однако вы можете более равномерно распределить «шумные» приложения в своем кластере Kubernetes, используя определения соответствия/несоответствия (affinity/antiaffinity) модулей Pod.

# Создание модулей Pod

Для создания так называемого контейнера вызывается множество примитивов Linux:
- kubelet выясняет, что должен запустить контейнер;
- затем kubelet (обращением к среде выполнения контейнеров) запускает приостановленный контейнер (так называемый контейнер pause), что дает ОС Linux время на создание сети для контейнера. Этот приостановленный контейнер является предшественником фактического приложения, которое будет запущено. Его цель – создать дом для начальной загрузки нового сетевого процесса контейнера и его идентификатора процесса (PID);

### Что такое примитивы Linux?

Примерами таких примитивов могут служить такие инструменты, как iptables, ls, mount и многие другие базовые программы, доступные в большинстве дистрибутивов Linux. Знание основ этих инструментов дает мощный толчок в понимании множества новых плагинов и надстроек в экосистеме Kubernetes:
- сетевой прокси-сервер kube-proxy создает правила iptables, и эти правила часто приходится проверять для устранения проблем с сетью контейнеров в больших кластерах. Получить эти правила можно, запустив команду iptables -L в узле Kubernetes. Провайдеры Container Network Interface (CNI) тоже используют этот сетевой прокси-сервер
- интерфейс Container Storage Interface (CSI) определяет сокет для взаимодействий kubelet с технологиями хранения. С помощью команды mount можно увидеть смонтированные в кластере контейнеры и тома, управляемые платформой Kubernetes, не привлекая kubectl и другие инструменты, не входящие в стандартную конфигурацию ОС.
- команды среды выполнения контейнеров, такие как unshare и mount, используются при создании изолированных процессов.

Примитивы Linux почти всегда представляют свои операции как операции с каким-либо файлом, потому что все, что вам нужно построить с помощью Kubernetes, изначально создавалось для работы в Linux, а Linux изначально разрабатывалась для использования файловой абстракции в качестве примитива управления.

Важной чертой примитивов Linux: их можно комбинировать в операции более высокого уровня. Используя канал (|), можно получить вывод одной команды и передать его для обработки другой команде. Например, проверка работоспособности etcd внутри кластера. Внутри контейнера на узле, где запущены компоненты плоскости управления Kubernetes, можно выполнить следующую команду:
```
ls /var/log/containers/ | grep etcd
```
Можно узнать, где находятся ресурсы конфигурации, связанные с etcd, выполнив примерно такую команду:
```
find /etc | grep etcd; find /var | grep etcd
```
### Предварительные условия для запуска модуля Pod

Для создания модуля Pod мы полагаемся на возможности изоляции, сетевых взаимодействий и управления процессами. Все это может быть реализовано с помощью утилит, уже доступных в ОС Linux. На самом деле некоторые из этих утилит можно считать обязательными, потому что без них kubelet не сможет выполнить действия, необходимые для запуска модуля Pod. 

Программы (или примитивы), на которые мы полагаемся в повседневной работе с кластерами Kubernetes:
- **swapoff** – команда, отключающая подкачку памяти, что является известным предварительным условием для запуска Kubernetes, позволяющим исключить конкуренцию за процессор и память;
- **iptables** – основное требование (обычно) сетевого прокси-сервера, который создает правила iptables для отправки служебного трафика модулям Pod;
- **mount** – эта команда проецирует ресурс в определенное место в файловой системе;
- **systemd** – эта команда обычно запускает kubelet – основной процесс, управляющий всеми контейнерами в кластере;
- **socat** – эта команда позволяет установить двунаправленную связь между процессами; socat обеспечивает правильное функционирование команды kubectl port-forward;
- **nsenter** – инструмент для входа в различные пространства имен процесса и просмотра происходящего (с точки зрения сети, хранилища или процесса). Пространство имен Linux имеет определенные ресурсы, к которым невозможно обратиться из внешнего мира. Например, уникальный IP-адрес модуля Pod в кластере Kubernetes не используется другими модулями, даже на том же узле, потому что каждый модуль работает в отдельном пространстве имен;
- **unshare** – команда, позволяющая запускать дочерние процессы, выполняющиеся изолированно, **unshare** также может изолировать точки монтирования (каталог /) и сетевые пространства имен (IP-адреса), и поэтому ее можно считать прямым аналогом команды docker run в ОС Linux;
- **ps** – программа, отображающая список запущенных процессов. Агент kubelet должен постоянно следить за процессами, чтобы всегда быть в курсе, например, когда они завершаются. С помощью команды ps можно определить, имеются ли в кластере процессы-зомби, не начал ли привилегированный контейнер проявлять неуправляемое поведение.

### Исследование зависимостей модуля Pod от Linux

Жизненный цикл модуля Pod – циклический процесс, отражающий фундаментальный цикл управления, который определяет, что делает сам агент kubelet во время работы. Поскольку контейнеры в модуле Pod могут выйти из строя в любой момент, на этот случай существует цикл управления, возвращающий их к жизни. Можно сказать, что сам Kubernetes – это всего лишь сложно организованный набор циклов управления, которые позволяют автоматически запускать и управлять контейнерами в больших масштабах. Пока kubelet работает, он выполняет непрерывный цикл согласования, в котором проверяются и запускаются модули Pod. После запуска модуля Pod в Kubernetes объект Pod на сервере API хранит полную информацию о состоянии модуля.
```
kubectl get pods -o yaml
```
Одним из параметров, которые Kubernetes определяет для всех своих модулей Pod, является default-token. Он предоставляет модулям сертификат, позволяющий связываться с сервером API и «звонить домой». В дополнение к томам Kubernetes мы передаем нашим модулям информацию о DNS.
```
kubectl exec -t -i core-k8s mount | grep resolv.conf
```
В большинстве окружений Linux то, что мы называем контейнерами, – это просто процессы, созданные с помощью нескольких механизмов изоляции, позволяющих им уживаться с сотнями других процессов в кластере.

### Создание модуля Pod с нуля

Четыре основных аспекта модуля Pod:
- хранилище;
- IP-адрес;
- изолированную сеть;
- идентификатор процесса.

Для начала создадим контейнер в самом прямом смысле – папку, в которой есть именно все, что нужно для запуска командной оболочки Bash, и больше ничего. Это делается с помощью известной команды **chroot**.

Назначение **chroot** – создать изолированную корневую файловую систему для процесса. Делается это в три шага.
- Выбор программы, которую требуется запустить, и где в файловой системе она должна работать.
- Создать среду для запуска процесса. В каталоге lib64 в Linux находится множество программ, которые необходимы даже для запуска простой командной оболочки, такой как Bash. Их нужно загрузить в новую корневую файловую систему.
- Скопировать программу для запуска в chroot-окружение.

Наконец, можно запустить программу, и она будет полностью изолирована от исходной файловой системы: она не сможет видеть или изменять другую информацию в вашей файловой системе.
