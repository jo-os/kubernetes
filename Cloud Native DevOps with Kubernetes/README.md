# Kubernetes

**Дирижирование оркестром контейнеров**

Оркестратор контейнеров: программный компонент, предназначенный для объединения множества разных серверов в кластер Кластер — это своего рода унифицированная вычислительная подложка, которая, с точки зрения пользователя, выглядит как компьютер очень высокой мощности, способный работать с контейнерами.

Термин «оркестратор контейнеров» обычно относится к одному сервису, который занимается планированием и оркестрацией кластера, а также управлением им.
- Оркестрация означает координацию и выстраивание цепочки из разных действий для достижения общей цели. 
- Планирование же означает управление доступными ресурсами и направление рабочих заданий туда, где они могут быть выполнены наиболее эффективно.
- Управление кластером является объединение нескольких физических или виртуальных серверов в унифицированную, надежную, отказоустойчивую и довольно цельную группу

В 2014 году компания Google основала открытый проект под названием Kubernetes (от греческого слова — «рулевой, пилот»).

**Что делает платформу Kubernetes такой ценной**

Kubernetes занимается тем же, чем и самые лучшие системные администраторы: автоматизацией, централизованным ведением журнала, мониторингом, обеспечивает отказоустойчивость. Балансировка нагрузки и автомасштабирование, встроены в ядро Kubernetes, Kubernetes отличается обширной и постоянно растущей экосистемой.

**Kubernetes облегчает развертывание**
- Благодаря тому что Kubernetes выполняет плавающие обновления по умолчанию, приобрели популярность развертывания с нулевым временем простоя
- Kubernetes поддерживает автомасштабирование
- Избыточность и отказоустойчивость встроены в Kubernetes

**Kubernetes не решает все проблемы**
- Kubernetes просто не очень хорошо подходит для некоторых структур (таких как базы данных).
- некоторые задачи не требуют Kubernetes и могут работать на платформах, которые иногда называют бессерверными (функции как сервис (functions as a service, FaaS))

**Облачная ориентированность**

Термин «облачно-ориентированный» (cloud native) становится все более популярным сокращением, которое описывает современные приложения и сервисы, пользующиеся преимуществами облаков, контейнеров и оркестрации

Характеристики облачно-ориентированных систем:
- Автоматизируемость
- Универсальность и гибкость
- Устойчивость и масштабируемость
- Динамичность
- Наблюдаемость
- Распределенность

# Первые шаги с Kubernetes

Запуск приложения
```
kubectl run demo --image=cloudnatived/demo:hello --port=9999 --labels app=demo deployment.apps "demo" created
```
Перенаправление портов
```
kubectl port-forward deploy/demo 9999:8888
```
Просмотр pods
```
kubectl get pods --selector app=demo
```
# Размещение Kubernetes

**Архитектура кластера**

«Мозг» кластера называется **управляющим уровнем**. Управляющий уровень на самом деле состоит из нескольких компонентов.
- kube-apiserver — это внешний сервер для управляющего уровня, который обрабатывает API-запросы
- etcd — база данных, в которой Kubernetes хранит всю информацию о существующих узлах, ресурсах кластера
- kube-scheduler определяет, где будут запущены свежесозданные pod-оболочки.
- kube-controller-manager отвечает за запуск контроллеров ресурсов, таких как развертывания.
- cloud-controller-manager взаимодействует с облачным провайдером (в облачных кластерах), управляя такими ресурсами, как балансировщики нагрузки и дисковые тома.

Участники кластера, которые **выполняют компоненты управляющего уровня**, называются **ведущими узлами**.

Участники кластера, которые **выполняют пользовательские рабочие задания**, называются **рабочими узлами**.

Каждый рабочий узел в кластере Kubernetes отвечает за следующие компоненты.
- kubelet отвечает за управление средой выполнения контейнера, в которой запускаются рабочие задания, запланированные для узла, а также за мониторинг их состояния.
- kube-proxy занимается сетевой магией, которая распределяет запросы между pod-оболочками на разных узлах, а также между pod-оболочками и Интернетом.
- Среда выполнения контейнеров запускает и останавливает контейнеры, а также отвечает за их взаимодействие.

**Высокая доступность**

У правильно сконфигурированного управляющего уровня Kubernetes есть несколько ведущих узлов, что делает его высокодоступным. База данных etcd реплицируется между несколькими узлами и может пережить отказ отдельных копий при условии наличия кворума из более чем половины реплик etcd.

**Отказ управляющего уровня**

Если вы остановите все ведущие узлы в своем кластере, pod-оболочки на рабочих узлах продолжат функционировать — по крайней мере какое-то время. Однако вы не сможете развертывать новые контейнеры или менять какие-либо ресурсы Kubernetes, а такие контроллеры, как развертывания, перестанут действовать.

Вам необходимо запастись достаточным количеством ведущих узлов, чтобы кластер мог поддерживать кворум, даже если какой-то из узлов откажет. Для промышленных кластеров реалистичным минимумом является три узла.

**Отказ рабочего узла**

Отказ любого рабочего узла, не влечет за собой никаких существенных последствий: Kubernetes обнаружит сбой и перераспределит pod-оболочки этого узла. Главное, чтобы работал управляющий уровень.

**Установщики Kubernetes**

**kops** (kubernetes.io/docs/setup/production-environment/tools/kops) — это утилита командной строки для автоматического выделения кластеров, служит инструментом, предназначенным специально для AWS.

**Kubespray** фокусируется на установке Kubernetes на существующие компьютеры, особенно на локальные и физические серверы. Это инструмент для простого развертывания промышленных кластеров. Он предлагает множество возможностей, включая высокую доступность и поддержку нескольких платформ.

**TK8** (github.com/kubernauts/tk8) — утилита командной строки для создания кластеров Kubernetes, которая использует как Terraform (для создания облачных серверов), так и Kubespray (для установки на них Kubernetes). Она написана на Go и поддерживает установку на AWS, OpenStack и «чистые серверы». 

**Kubernetes: трудный путь**

**kubeadm** - Утилита kubeadm (kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm) входит в состав дистрибутива Kubernetes и должна помочь вам устанавливать и обслуживать кластеры в соответствии с лучшими рекомендациями. Многие инструменты и сервисы, используют kubeadm для выполнения административных операций,

**Tarmak** (blog.jetstack.io/blog/introducing-tarmak) — это инструмент для управления жизненным циклом кластеров Kubernetes, который должен упростить и сделать более надежными модификацию и обновления кластерных узлов. Tarmak использует Terraform для выделения узлов кластера и Puppet для управления конфигурацией на самих узлах.

**Rancher Kubernetes Engine** - RKE (github.com/rancher/rke) стремится быть простым и быстрым установщиком Kubernetes.

# Работа с объектами Kubernetes
**Надзор и планирование**

Для каждой программы, за которой нужно следить, Kubernetes создает соответствующий объект Deployment, записывающий некоторую связанную с ней информацию: имя образа контейнера, количество реплик (копий), которые вы хотите выполнять, и любые другие параметры, необходимые для запуска контейнера. В связке с ресурсом Deployment работает некий объект Kubernetes под названием контроллер. Контроллеры отслеживают ресурсы, за которые отвечают, убеждаясь в том, что те присутствуют и выполняются, а если заданное развертывание по какой-либо причине не имеет достаточного количества реплик, дополнительно их создают. На самом деле развертывание не управляет репликами напрямую: вместо этого оно автоматически создает сопутствующий объект под названием ReplicaSet, который сам этим занимается.

**Перезапуск контейнеров**

Большинство приложений Kubernetes должны работать долго и надежно, поэтому
подобное поведение имеет смысл: контейнер может остановиться по разным причинам, и в большинстве случаев реакцией живого оператора будет перезапуск — именно так по умолчанию и ведет себя Kubernetes. Задача развертывания состоит в том, чтобы отслеживать связанные с ним контейнеры и постоянно поддерживать определенное их количество.

**Обращение к развертываниям**

Просмотреть все активные развертывания в вашем текущем пространстве:
```
kubectl get deployments
kubectl describe deployments/demo - подробной информации о конкретном развертывании
```
**Pod-оболочки**

**Pod** — это объект Kubernetes, который представляет группу из одного или нескольких контейнеров

**Объекты ReplicaSet**

**ReplicaSet отвечает** за группу идентичных pod-оболочек (или реплик). Развертывания, в свою очередь, управляют объектами ReplicaSet и контролируют поведение реплик в момент их обновления — например, при выкатывании новой версии вашего приложения.

**Поддержание желаемого состояния**

Контроллеры Kubernetes непрерывно сравнивают желаемое состояние, указанное каждым ресурсом, с реальным состоянием кластера и вносят необходимые корректировки. Этот процесс называют циклом согласования, поскольку он все время повторяется в попытке согласовать текущее состояние с желаемым. Создав развертывание, вы сообщили Kubernetes о том, что pod-оболочка должна работать **всегда**.

**Планировщик Kubernetes**

Развертывание создаст pod-оболочки, а Kubernetes при необходимости их запустит. За эту часть процесса отвечает компонент Kubernetes под названием «планировщик». Задача планировщика — следить за этой очередью, взять из нее следующую запланированную pod-оболочку и найти узел, на котором ее можно запустить. При выборе подходящего узла планировщик будет исходить из нескольких разных критериев, включая ресурсы, запрашиваемые pod-оболочкой. Как только выполнение pod-оболочки было запланировано, утилита kubelet, работающая на соответствующем узле, подхватывает ее и производит запуск ее контейнера.

**Ресурсы являются данными**

Все ресурсы Kubernetes, такие как развертывания и pod-оболочки, представлены записями во внутренней базе данных. Цикл согласования следит за любыми изменениями в записях и предпринимает соответствующие действия. На самом деле команда kubectl run лишь добавляет в базу данных новую запись о развертывании, а система делает все остальное. Но для взаимодействия с Kubernetes вовсе не обязательно использовать команду kubectl run — вы можете создавать манифесты ресурсов.

**Манифесты развертываний**

deployment.yaml
```yml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: demo
  labels:
    app: demo
spec:
  replicas: 1
  selector:
    matchLabels:
      app: demo
template:
  metadata:
    labels:
      app: demo
spec:
  containers:
    - name: demo
    image: cloudnatived/demo:hello
    ports:
    - containerPort: 8888
```
**Использование команды kubectl apply**

Передавать YAML-манифесты вашему кластеру, используя команду kubectl apply.
```
kubectl apply -f k8s/deployment.yaml
```
Для подключения к pod-оболочке с помощью веб-браузера надо создать сервис — ресурс Kubernetes, который позволяет подключаться к развернутым pod-оболочкам.

**Ресурсы типа «сервис»**

Ресурс типа «сервис» предоставляет один несменяемый IP-адрес или такое же доменное имя, которые автоматически перена- правляют на любую подходящую pod-оболочку. Сервис можно считать веб-прокси или балансировщиком нагрузки, который направляет запросы к группе внутренних pod-оболочек.

service.yaml
```yaml
apiVersion: v1
kind: Service
metadata:
  name: demo
  labels:
    app: demo
spec:
ports:
  - port: 9999
  protocol: TCP
    targetPort: 8888
  selector:
    app: demo
  type: ClusterIP
```
Параметр selector говорит сервису, как перенаправлять запросы к конкретным pod-оболочкам. Сервис предоставляет запросам единую точку входа в эти pod-оболочки.
```
kubectl apply -f k8s/service.yaml
kubectl port-forward service/demo 9999
```
**Обращение к кластеру с помощью kubectl**

С помощью kubectl get можно запрашивать pod-оболочки и развертывания. Эту команду также можно использовать для просмотра узлов вашего кластера:
```
kubectl get nodes
```
Вывести ресурсы всех типов, выполните команду - kubectl get all

Получить исчерпывающую информацию об отдельной pod-оболочке (или любом другом ресурсе), выполните kubectl describe:
```
kubectl describe pod/demo-dev-6c96484c48-69vss
```
## Helm: диспетчер пакетов для Kubernetes

Один из популярных диспетчеров пакетов для Kubernetes называется Helm. helm для установки и конфигурации приложений
(собственных или чужих) и создавать пакеты, которые полностью описывают все необходимые для работы приложения ресурсы, включая их зависимости и настройки. Пакеты в Helm называются чартами (charts).

Установка Helm - Следуйте инструкциям по установке Helm (helm.sh/docs/using_helm/#installing-helm) для вашей операционной системы.

Установка чарта Helm
```
helm install --name demo ./k8s/demo
```
Helm создал ресурс Deployment и Service, команда helm install создает объект Kubernetes под названием «выпуск» (release).

**Чарты, репозитории и выпуски**
- Чарт — пакет Helm с определениями всех ресурсов, необходимых для выполнения приложения в Kubernetes.
- Репозиторий — место, где можно делиться своими чартами и загружать чужие.
- Выпуск — конкретный экземпляр чарта, запущенный в кластере Kubernetes

У каждого выпуска есть уникальное имя, которое можно указать в команде helm install с помощью флага **-name**

**Вывод списка выпусков Helm**

Проверить, какие выпуски запущены на данный момент:
```
helm list
```
Вывести состояние конкретного выпуска, передайте его имя команде **helm status**.

## Управление ресурсами

**Запросы ресурсов**

Запрос ресурса в Kubernetes определяет минимальный объем этого ресурса, который необходим для работы pod-оболочки. Например, запрос 100m (100 миллипроцессоров) и 250Mi (250 МиБ памяти) означает, что pod-оболочка не может быть назначена узлу с меньшим количеством доступных ресурсов. Если в кластере нет ни одного узла с достаточной мощностью, pod-оболочка будет оставаться в состоянии pending, пока такой узел не появится.
```
resources:
  requests:
    memory: "10Mi"
    cpu: "100m"
```
**Лимит на ресурс** определяет максимальное количество этого ресурса, которое pod-оболочке позволено использовать. Если pod-оболочка попытается занять больше выделенного ей лимита на процессор, производительность будет снижена. Pod-оболочка, пытающаяся использовать больше, чем указано в лимите на память, будет принудительно остановлена, и ее выполнение, если это возможно, снова окажется запланировано.
```
resources:
  limits:
    memory: "20Mi"
    cpu: "250m"
```
Kubernetes допускает **отрицательный баланс ресурсов**, когда сумма всех лимитов у контейнеров одного узла превышает общее количество ресурсов, которыми узел обладает. Общее количество потребляемых ресурсов начнет приближаться к максимальной мощности узла и Kubernetes начнет удалять контейнеры более агрессивно. В условиях нехватки ресурсов могут быть остановлены даже те контейнеры, которые исчерпали запрошенные ресурсы, а не лимиты. При прочих равных, когда возникает необходимость в удалении pod-оболочек, Kubernetes начинает с тех, которые больше всего превысили запрошенные ресурсы.

**Управление жизненным циклом контейнера**

Контейнеризированные приложения довольно часто входят в ступор: их процесс все еще выполняется, но больше не обслуживает никакие запросы. Kubernetes нужен какой-то способ для обнаружения подобных ситуаций, чтобы решить проблему за счет перезапуска контейнера.

**Проверки работоспособности**

Если приложение отвечает с помощью HTTP-кода вида 2xx или 3xx, Kubernetes считает его активным.
Для контейнера с HTTP-сервером определение проверки работоспособности обычно выглядит примерно так:
```
livenessProbe:
  httpGet:
    path: /healthz
    port: 8888
  initialDelaySeconds: 3
  periodSeconds: 3
```
**Задержка и частота проверки**

Поле initialDelaySeconds позволяет указать время ожидания перед первой проверкой работоспособности, чтобы избежать убийственного цикла (loop of the death). Поле periodSeconds определяет, как часто следует выполнять проверку работоспособности: в данном примере это делается каждые три секунды.

**Проверки готовности**

Проверки готовности и работоспособности имеют общее происхождение, но разную семантику. Если ваше приложение не начинает прослушивать HTTP, пока не будет готово к обработке запросов, проверки готовности и работоспособности могут выглядеть одинаково:
```
readinessProbe:
  httpGet:
    path: /healthz
    port: 8888
  initialDelaySeconds: 3
  periodSeconds: 3
```
Контейнер, не прошедший проверку готовности, удаляется из любых сервисов, совпавших с заданной pod-оболочкой. Это похоже на удаление неисправного узла из пула балансировщика нагрузки: к pod-оболочке не будет направляться трафик, пока она опять не начнет успешно проходить проверку готовности.

**Проверки готовности на основе файла** - Проверка готовности такого рода может быть полезной. Например, если нужно временно выключить контейнер с целью отладки, к нему можно подключиться и удалить файл /tmp/healthy.

**minReadySeconds** - для контейнера можно установить поле minReadySeconds. Контейнеры или pod-оболочки не будут считаться готовыми, пока с момента успешной проверки готовности не пройдет minReadySeconds секунд (по умолчанию 0).

**PodDisruptionBudget** - Иногда Kubernetes нужно остановить ваши pod-оболочки, даже если они в полном порядке и готовы к работе (этот процесс называется выселением). Возможно, узел, на котором они размещены, очищается перед обновлением и pod-оболочки необходимо переместить на другой узел. Ресурс PodDisruptionBudget позволяет указать, сколько pod-оболочек заданного приложения допустимо к потере в любой момент времени.

**minAvailable** - для определения минимального количества рабочих pod.

**maxUnavailable** - это относится лишь к так называемому добровольному выселению, то есть инициированному системой Kubernetes. Если, к примеру, узел испытывает аппаратные неполадки или удаляется, его pod-оболочки выселяются принудительно, даже если это нарушает параметры PodDisruptionBudget.

**Использование пространств имен** 

Механизмом контроля за потреблением ресурсов в вашем кластере является использование пространств имен. Пространство имен в Kubernetes предоставляет способ разделения кластера на отдельные части.

Чтобы увидеть, какие пространства имен существуют в вашем кластере:
```
kubectl get namespaces
```
**Работа с пространствами имен**
Ваша команда будет использовать то пространство имен, которое вы укажете с помощью флага --namespace (сокращенно -n).
```
kubectl get pods --namespace prod
```
В Kubernetes пространства имен можно создавать с помощью ресурса Namespace:
```
apiVersion: v1
kind: Namespace
metadata:
  name: demo
```
Пространство имен можно использовать в качестве временного виртуального кластера, который, став ненужным, удаляется.

**Квоты на ресурсы**

Вы можете ограничить потребление процессорного времени, памяти и для заданных пространств имен
```
apiVersion: v1
kind: ResourceQuota
metadata:
  name: demo-resourcequota
spec:
  hard:
    pods: "100"
```
Применение этого манифеста к конкретному пространству имен (например, к demo) устанавливает жесткий лимит на запуск не более чем 100 pod-оболочек в этом пространстве.
```
kubectl create namespace demo
kubectl apply --namespace demo -f k8s/resourcequota.yaml
```
Проверить, активирован ли ресурс ResourceQuotas в конкретном пространстве имен:
```
kubectl get resourcequotas -n demo
```
**Оптимизация стоимости кластера**

**Оптимизация узлов**

Более крупные узлы могут быть более рентабельными, поскольку доля их ресурсов, доступных для ваших рабочих заданий, оказывается выше. Но, с другой стороны, потеря отдельного узла будет иметь более заметные последствия для доступной мощности вашего кластера. У мелких узлов также более высокая доля заблокированных ресурсов — порций памяти и процессорного времени, которые не используются и которые слишком малы для того, чтобы pod-оболочка могла их занять. Узлы лучше делать достаточно большими для выполнения как минимум пяти ваших типичных pod-оболочек. По умолчанию в Kubernetes действует лимит 110 pod-оболочек на узел, можете поднять его с помощью параметра --max-pods утилиты kubelet. Стремитесь к показателю 10–100 pod-оболочек на узел.

**Оптимизация хранилища** - Консоль вашего облачного провайдера или сервиса Kubernetes обычно умеет по-
казывать количество IOPS, используемое вашими узлами.

**Избавление от неиспользуемых ресурсов** - По мере увеличения вашего кластера Kubernetes вы будете обнаруживать множество неиспользуемых или потерянных ресурсов.

**Использование метаданных владельца** - Чтобы минимизировать неиспользуемые ресурсы, на уровне организации стоит
ввести правило, согласно которому каждый ресурс должен иметь информацию о своем владельце. Для этого можно использовать аннотации Kubernetes.
```
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: my-brilliant-app
  annotations:
    example.com/owner: "Customer Apps Team"   - информацию о владельце
```
Метаданные владельца должны указывать на человека или команду, с которыми можно связаться при возникновении вопросов относительно конкретного ресурса.

**Поиск малоиспользуемых ресурсов**

Каждая pod-оболочка должна предоставлять в виде показателя количество полученных запросов. Вы также можете проверить показатели загруженности процессора и памяти у каждой pod-оболочки в вашей веб-консоли, чтобы найти наименее загруженные.

**Удаление завершенных запланированных заданий**

Запланированные задания в Kubernetes — это pod-оболочки, которые выполняются единожды и не перезапускаюся после завершения работы. Однако в базе данных Kubernetes остаются Job-объекты, и если у вас наберется значительное количество завершенных заданий, это может повлиять на производительность API. Для удаления таких объектов предусмотрен
удобный инструмент **kube-job-cleaner**

**Использование принадлежности к узлам для управления планированием**

В Kubernetes можно использовать концепцию принадлежности узлов (node affinities), чтобы pod-оболочки, отказ которых недопустим, не размещались на прерываемых узлах. Чтобы планировщик Kubernetes никогда не разместил pod-оболочку на одном из таких узлов, добавьте следующий фрагмент в ее спецификацию.
```
affinity:
  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
        - matchExpressions:
          - key: cloud.google.com/gke-preemptible
            operator: DoesNotExist
```
Принадлежность requiredDuringScheduling... является обязательной: pod-оболочка, в которой она указана, никогда не будет запущена на узле, соответствующем выражению селектора (это называется жесткой принадлежностью

Мягкая принадлежность с противоположным смыслом
```
preferredDuringSchedulingIgnoredDuringExecution:
- preference:
  matchExpressions:
  - key: cloud.google.com/gke-preemptible
    operator: Exists
weight: 100
```
Означает следующее: «Если можешь — пожалуйста, размещай данную pod-оболочку на прерываемом узле; если нет — ничего страшного.

**Балансировка вашей рабочей нагрузки**

Суть проблемы в том, что планировщик перемещает pod-оболочки с одного узла на другой, только если они по какой-либо причине перезапускаются. К тому же задача планировщика — распределить рабочую нагрузку равномерно между узлами — иногда конфликтует с поддержанием высокой доступности отдельных сервисов. Одним из решений является использование инструмента под названием **Descheduler**. Для Descheduler можно задавать различные стратегии и линии поведения. Например, одна из его политик ищет малонагруженные узлы и переносит на них pod-оболочки с других узлов. Другая политика ищет pod-оболочки, две и более реплики которых размещены на одном узле, и выселяет их.

## Работа с кластерами

**Максимальный кластер**

1.12 официально поддерживает кластеры до 5000 узлов. В документации к Kubernetes говорится о том, что поддерживаемая конфигурация кластера не должна превышать 5000 узлов, 150 000 pod-оболочек, 300 000 контейнеров, а на одном узле не должно быть больше 100 pod-оболочек.

**Федеративные кластеры** - Федерация позволяет синхронизировать два и более кластера, запуская на них идентичные задания.

**Типы облачных серверов** - Ведущие узлы в небольших кластерах (до пяти узлов) должны иметь как минимум один виртуальный процессор (vCPU) и 3–4 ГиБ памяти. 

**Обратное масштабирование**

В принципе, у Kubernetes нет никаких проблем и с обратным масштабированием. Вы можете приказать системе очистить узлы, подлежащие удалению, и она постепенно выключит pod-оболочки на этих узлах или куда-нибудь их переместит.

Большинство инструментов для управления кластером выполняют очищение узлов автоматически, но также можно использовать команду **kubectl drain**, чтобы сделать это вручную. Если у кластера достаточно свободной мощности для перераспределения «обреченных» pod-оболочек, вы сможете удалить их сразу после успешного очищения узлов. Очистка позволяет pod-оболочкам корректно завершить свою работу, убрать за собой, а также, если необходимо, сохранить какое-либо состояние.

**Автомасштабирование** - автомасштабирование — автоматическое увеличение или уменьшение количества серверов в группе на основе какого-то показателя или графика.

**Проверка на соответствие** - платформа Kubernetes содержит набор тестов, позволяющий подтвердить, что кластер соответствует спецификации, то есть удовлетворяет основному набору требований для заданной версии Kubernetes. Соответствие стандартам — это лишь начальное условие, которое должно выполняться любым промышленным кластером. Однако в Kubernetes существует много распространенных проблем с конфигурацией и рабочей нагрузкой:
- использование слишком больших образов контейнеров может привести к потере значительного количества времени и ресурсов кластера;
- развертывания с единственной репликой pod-оболочки не являются высокодоступными;
- выполнение процессов в контейнерах от имени администратора представляет потенциальный риск для безопасности

Стандартным инструментом для выполнения проверок является система **Sonobuoy** от Heptio

**K8Guard** - Утилита K8Guard, разработанная компанией Target, умеет искать распространенные проблемы в кластерах

**Copper** (copper.sh) — это инструмент для проверки манифестов Kubernetes перед их развертыванием; он отмечает распространенные проблемы или применяет отдельные политики.

**kube-bench** — это инструмент для аудита кластеров Kubernetes с помощью набора тестов производительности, разработанных Центром интернет-безопасности.

**Ведение журнала аудита для Kubernetes** - Если включить ведение этого журнала, все запросы к API кластера будут записываться с пометкой о том, когда и кто их сделал.

**Хаотическое тестирование** - Такой вид автоматического, произвольного вмешательства в промышленные сервисы иногда называют тестом обезьяны в честь инструмента Chaos Monkey («хаотическая обезьяна»), разработанного компанией Netflix для тестирования своей инфраструктуры.

**chaoskube** (github.com/linki/chaoskube) случайным образом удаляет pod-оболочки вашего кластера.

**kube-monkey** (github.com/asobti/kube-monkey) запускается в заранее установленное время и формирует график развертываний, которые будут объектами тестирования на протяжении всего дня.

**PowerfulSeal** (github.com/bloomberg/powerfulseal) — это открытый инструмент для хаотического тестирования Kubernetes, который работает в двух режимах: интерактивном и автономном.

## Продвинутые инструменты для работы с Kubernetes

**kubectl** - главный инструмент для взаимодействия с Kubernetes

**Псевдонимы командной оболочки** - Чтобы сделать свою жизнь проще, большинство пользователей Kubernetes первым
делом создают псевдоним командной оболочки для kubectl.
```
alias k=kubectl
 - k get pods
alias kg=kubectl get
alias kgdep=kubectl get deployment
alias ksys=kubectl --namespace=kube-system
alias kd=kubectl describe
```
**Использование коротких флагов**

--namespace можно сократить до -n
```
kubectl get pods -n kube-system
```
Для работы с ресурсами, которые соответствуют какому-то набору меток. Для этого предусмотрен флаг --selector можно сократить до -l.
```
kubectl get pods -l environment=staging
```
**Сокращение названий типов ресурсов**
```
kubectl get po
kubectl get deploy
kubectl get svc
kubectl get ns
```
**Справка по ресурсам Kubernetes**
```
kubectl -h: - полный обзор доступных команд
kubectl get -h - подробное описание команды
```
kubectl предоставляет справку и для объектов Kubernetes, таких как развертывания или pod-оболочки. Команда kubectl explain выводит документацию для заданного типа ресурсов:
```
kubectl explain pods
```
**Отображение более подробного вывода**

С помощью флага -o wide можно получить дополнительную информацию
```
kubectl get pods -o wide
kubectl get nodes -o wide
```
По умолчанию команда kubectl get возвращает данные в виде обычного текста, но вы можете вывести их в формате JSON:
```
kubectl get pods -n kube-system -o json
```
Вывод можно отфильтровать с помощью других инструментов, таких как утилита jq.
```
kubectl get pods -n kube-system -o json | jq '.items[].metadata.name'
```
**Наблюдение за объектами**

У kubectl есть флаг --watch
```
kubectl get pods --watch
```
**Описание объектов**
Получить по-настоящему подробную информацию об объектах Kubernetes, можно воспользоваться командой kubectl describe:
```
kubectl describe pods demo-d94cffc44-gvgzm
```
Раздел Events особенно полезен для отладки контейнеров, которые не работают должным образом, поскольку в нем записан каждый этап жизненного цикла контейнера вместе с любыми возникшими ошибками.

**Работа с ресурсами. Императивные команды kubectl**

Большинство ресурсов можно создавать явным образом с помощью команды kubectl create:
```
kubectl create namespace my-new-namespace
kubectl delete namespace my-new-namespace - kubectl delete и удалит ресурс
kubectl edit deployments my-deployment - просмотреть и модифицировать ресурсы
```
Если вы допустили какие-либо ошибки kubectl об этом сообщит и откроет файл, чтобы вы могли исправить проблему.

**Когда не следует использовать императивные команды**

Они могут быть крайне полезными для быстрого тестирования или проверки новых идей, но их основная проблема в том, что у вас нет единого источника истины. Как только вы выполните императивную команду, состояние вашего кластера перестанет быть синхронизированным с файлами манифестов, хранящимися в системе контроля версий. Проверить изменения можно с помощью команды **kubectl diff**

**Генерация манифестов ресурсов**

Императивные команды могут сэкономить немало времени при создании с нуля YAML-файлов для Kubernetes. Вы можете сгенерировать YAML-манифест с помощью kubectl:
```
kubectl run demo --image=cloudnatived/demo:hello --dry-run -o yaml
```
Флаг --dry-run говорит kubectl о том, что вместо создания самого ресурса kubectl следует вывести его манифест. Флаг -o yaml позволяет отобразить манифест ресурса в формате YAML. Можете сохранить этот вывод в файл, отредактировать его и применить для создания ресурса в кластере:
```
kubectl run demo --image=cloudnatived/demo:hello --dry-run -o yaml > deployment.yaml
```
**Экспорт ресурсов**

kubectl может помочь с созданием манифестов не только для новых, но и для уже существующих ресурсов. Чтобы это сделать, укажите для команды kubectl get флаг --export:
```
kubectl get deployments newdemo -o yaml --export >deployment.yaml
```
**Сравнение ресурсов**

Прежде чем применять манифесты Kubernetes с помощью команды kubectl apply, было бы крайне полезно увидеть, что же на самом деле изменится в кластере. Для этого предусмотрена команда kubectl diff:
```
kubectl diff -f deployment.yaml
```
Можно убедиться, что вносимые вами изменения приведут именно к тем результатам, которых вы ожидали. Вы также будете предупреждены, если состояние активного ресурса рассинхронизировано с YAML-манифестом

**Работа с контейнерами**

**Просмотр журнальных записей контейнера** - одним из самых полезных источников информации являются его журнальные записи. С точки зрения Kubernetes журналом считается все, что контейнер записывает в потоки вывода сообщений об ошибках.

Исследование журнальных сообщений отдельных контейнеров по-прежнему очень полезно для отладки - **kubectl logs**
```
kubectl logs -n kube-system --tail=20 kube-dns-autoscaler-69c5cbdcdd-94h7f
```
Чтобы следить за контейнером и направлять его журнальный вывод в терминал, используйте флаг --follow
```
kubectl logs --namespace kube-system --tail=10 --follow etcd-docker-for-desktop
```
**Подключение к контейнеру** - позволит наблюдать вывод контейнера напрямую - команда **kubectl attach**
```
kubectl attach demo-54f4458547-fcx2n
```
**kubespy** - может наблюдать за отдельными ресурсами кластера и показывать вам, что с ними со временем происходит

**Перенаправление порта контейнера** - kubectl port-forward - с ее помощью также можно перенаправить порт контейнера
```
kubectl port-forward demo-54f4458547-vm88z 9999:8888
```
**Выполнение команд внутри контейнеров** - С помощью **kubectl exec** в любом контейнере можно запустить любую команду, включая командную оболочку
```
kubectl exec -it alpine-7fd44fc4bf-7gl4n /bin/sh
```
Если pod-оболочка содержит больше одного контейнера, kubectl exec по умолчанию выполняет команду только в первом из них. Но вы также можете указать нужный вам контейнер с помощью флага -c:
```
kubectl exec -it -c container2 POD_NAME /bin/sh
```
**Запуск контейнеров с целью отладки**
```
kubectl run NAME --image=IMAGE --rm --it --restart=Never --command --...
```
---rm. Этот флаг говорит Kubernetes о необходимости удалить образ контейнера после завершения его работы, чтобы тот не занимал место в локальном хранилище узла.
---it. Запускает контейнер интерактивно (i — interactively) в локальном терминале (t — terminal), чтобы вы могли просматривать его вывод и при необходимости отправлять ему информацию о нажатых клавишах.
---restart=Never. Говорит Kubernetes не перезапускать контейнер каждый раз, когда тот завершает работу (поведение по умолчанию). Мы можем отключить стандартную политику перезапуска, так как нам нужно запустить контейнер лишь один раз.
---command--. Вместо точки входа контейнера по умолчанию указывает команду, которую нужно выполнить. Все, что идет за --, будет передано контейнеру в виде командной строки, включая аргументы.

**Использование команд BusyBox**

**busybox** - является особенно полезным ввиду наличия в нем большого количества самых востребованных в Unix команд, таких как cat, echo, find, grep и kill. Чтобы получить интерактивную командную оболочку в своем кластере:
```
kubectl run busybox --image=busybox:1.28 --rm --it --restart=Never /bin/sh
```
**Добавление BusyBox в ваш контейнер**

Самый простой способ сделать отладку контейнера легкой и сохранить при этом его очень маленький размер — скопировать в него исполняемый файл busybox во время сборки.
```
COPY --from=busybox:1.28 /bin/busybox /bin/busybox
контейнер остался очень маленьким, но теперь вы можете получить в нем командную оболочку, запустив:
kubectl exec -it POD_NAME /bin/busybox sh
```
**Контексты и пространства имен**

kubectl предлагает концепцию контекстов. Контекст — это сочетание кластера, пользователя и пространства имен. Когда вы запускаете команды kubectl, они всегда выполняются в текущем контексте.
```
kubectl config get-contexts
CURRENT    NAME                  CLUSTER          AUTHINFO        NAMESPACE
           gke                   gke_test_us-w    gke_test_us     myapp
*          docker-for-desktop    docker-for-d     docker-for-d
```
Это контексты, о которых kubectl в настоящее время знает. Каждый контекст имеет имя и ссылается на определенный кластер, имя пользователя, который в нем аутентифицирован, и пространство имен внутри этого кластера. Текущий контекст помечен звездочкой * в первом столбце. Если мы сейчас запустим команду kubectl, она будет выполнена в пространстве имен по умолчанию кластера Docker Desktop.

С помощью команды kubectl config use-context можно переключиться на другой контекст:
```
kubectl config use-context gke
```
Контексты — это своего рода закладки, позволяющие легко переходить в определенное пространство имен определенного кластера. Чтобы создать новый контекст, выполните **kubectl config set-context**:
```
kubectl config set-context myapp --cluster=gke --namespace=myapp
```
Вы забыли, в каком контексте находитесь, команда kubectl config currentcontext напомнит:
```
kubectl config current-context
```
Для более быстрого переключения между контекстами kubectl можно использовать инструменты **kubectx** и **kubens**
```
kubectx docker-for-desktop - переключать контексты
kubectx -       - быстрый переход к предыдущему контексту
kubens kube-system - переключаться между пространствами имен
kubens -
```
## Работа с контейнерами

**Контейнеры и pod-оболочки** - Pod-оболочка — это единица планирования в Kubernetes. Pod-объект представляет собой контейнер или группу контейнеров, с его помощью в Kubernetes работают все остальные компоненты.

**Контейнер** — это стандартизированный пакет, который содержит фрагмент программного обеспечения вместе с зависимостями контейнера, его конфигурацией, данными. С точки зрения операционной системы контейнер представляет собой изолированный процесс, который находится в своем собственном пространстве имен. Практика показывает, что лучше поручить контейнеру какую-то одну функцию. У контейнера также есть точка входа — команда, которая запускается при старте. Обычно она приводит к созданию единого процесса для выполнения команды, хотя какие-то приложения запускают несколько вспомогательных или рабочих подпроцессов.

**Pod-объект** представляет собой группу контейнеров, которые должны взаимодействовать и обмениваться данными; планировать, запускать и останавливать их нужно вместе, и находиться они должны на одном и том же физическом компьютере.

**Безопасность контейнеров**

Запускать процессы от имени пользователя root, когда этого не требуется, — плохая идея. Она противоречит принципу минимальных привилегий. Они должны работать от имени обычного пользователя.
```
containers:
- name: demo
  image: cloudnatived/demo:hello
  securityContext:
    runAsUser: 1000
```
**Блокирование контейнеров с администраторскими привилегиями**
```
securityContext:
  runAsNonRoot: true
```
**Настройка файловой системы только для чтения**
```
securityContext:
  readOnlyRootFilesystem: true
```
**Отключение повышения привилегий**
```
securityContext:
  allowPrivilegeEscalation: false
```
**Мандаты**

Механизм мандатов в Linux является шагом вперед. Он четко определяет, что программа может делать: загружать модули ядра, напрямую выполнять сетевые операции ввода/вывода, обращаться к системным устройствам
```
securityContext:
  capabilities:
    drop: ["CHOWN", "NET_RAW", "SETPCAP"]
    add: ["NET_ADMIN"]
```
Некоторые параметры контекста безопасности можно устанавливать и на уровне pod-оболочки
```
spec:
  securityContext:
  runAsUser: 1000
  runAsNonRoot: false
  allowPrivilegeEscalation: false
```
Можно создать для приложения отдельную служебную учетную запись, привязать ее к необходимым ролям и прописать в конфигурации pod-оболочки. Для этого укажите в поле serviceAccountName спецификации pod-оболочки имя служебной учетной записи:
```
spec:
  serviceAccountName: deploy-tool
```
**Политики перезапуска** - по умолчанию используется политика перезапуска Always, но вы можете указать вместо нее OnFailure или Never.
```
spec:
  restartPolicy: OnFailure
```
**imagePullSecrets** - если вы используете приватный реестр? Как передать Kubernetes учетные данные для аутентификации в таком реестре? Сделать это можно с помощью поля imagePullSecrets в pod-оболочке. Для начала учетные данные необходимо сохранить в объекте Secret, если объект Secret называется registry-creds:
```
spec:
imagePullSecrets:
- name: registry-creds
```
## Управление pod-оболочками
